import os
import time
import sqlite3
import re
from datetime import datetime
from dotenv import load_dotenv

from src.collector.reddit_collector import RedditCollector
from src.collector.google_searcher import GoogleSearcher
from src.processor.claude_processor import ClaudeProcessor
from src.painter.local_painter import LocalPainter
from src.affiliate.coupang_helper import CoupangHelper

load_dotenv()

class GTBManager:
    def __init__(self):
        self.db_path = "data/gtb_storage.db"
        self._init_db()
        print("[*] GTB ë§¤ê±°ì§„ ì—”ì§„ ìµœì í™” ë²„ì „ ê°€ë™ ì¤‘...")
        self.collector = RedditCollector()
        self.searcher = GoogleSearcher()
        self.processor = ClaudeProcessor()
        self.painter = LocalPainter()
        self.affiliate = CoupangHelper()
        
        self.category_map = {
            "Supplements": "ê±´ê°•",
            "Gadgets": "ITí…Œí¬",
            "HomeImprovement": "ë¼ì´í”„",
            "Technology": "ITí…Œí¬",
            "BuyItForLife": "ë¼ì´í”„"
        }
        self.target_subreddits = list(self.category_map.keys())

    def _init_db(self):
        os.makedirs("data", exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("CREATE TABLE IF NOT EXISTS posts (reddit_id TEXT PRIMARY KEY, title TEXT, processed_date TEXT, file_path TEXT)")
        conn.commit()
        conn.close()

    def is_already_processed(self, reddit_id):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM posts WHERE reddit_id = ?", (reddit_id,))
        result = cursor.fetchone()
        conn.close()
        return result is not None

    def mark_as_processed(self, reddit_id, title, file_path):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT INTO posts (reddit_id, title, processed_date, file_path) VALUES (?, ?, ?, ?)",
            (reddit_id, title, datetime.now().strftime("%Y-%m-%d %H:%M:%S"), file_path))
        conn.commit()
        conn.close()

    def sanitize_filename(self, filename):
        filename = re.sub(r'[\/:*?"<>|]', '', filename)
        filename = filename.replace(' ', '_')
        return filename[:50]

    def parse_claude_result(self, raw_text):
        data = {}
        patterns = {
            'title': r'TITLE:\s*(.*?)(?:\n---|\nSUMMARY:|$)',
            'summary': r'SUMMARY:\s*(.*?)(?:\n---|\nCONTENT:|$)',
            'content': r'CONTENT:\s*(.*?)(?:\n---|\nIMAGE_PROMPT:|$)',
            'image_prompt': r'IMAGE_PROMPT:\s*(.*?)(?:\n---|\nKEYWORDS:|$)',
            'keywords': r'KEYWORDS:\s*(.*)'
        }
        for key, pattern in patterns.items():
            match = re.search(pattern, raw_text, re.DOTALL | re.IGNORECASE)
            if match:
                data[key] = match.group(1).strip()
            else:
                data[key] = ""
        if not data.get('keywords') and data.get('title'):
            data['keywords'] = " ".join(data['title'].split()[:2])
        return data

    def run_pipeline(self):
        print("\n" + "="*60)
        print(f"ğŸš€ GTB ìë™ í¬ìŠ¤íŒ… ì‹œì‘ (ì•ˆì „ ëª¨ë“œ): {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)

        today_str = datetime.now().strftime("%Y%m%d")

        for sub in self.target_subreddits:
            # ìƒìœ„ 5ê°œê¹Œì§€ ê°€ì ¸ì™€ì„œ ì¤‘ë³µë˜ì§€ ì•Šì€ ê°€ì¥ ìµœì‹  ê¸€ í•˜ë‚˜ë¥¼ ì„ íƒ
            posts = self.collector.fetch_top_posts(sub, limit=5)
            category_name = self.category_map.get(sub, "ì¸ì‚¬ì´íŠ¸")
            
            published_in_sub = False
            for post in posts:
                if self.is_already_processed(post['id']):
                    print(f"[-] ì¤‘ë³µ ê±´ë„ˆë›°ê¸° ({sub}): {post['title'][:30]}...")
                    continue

                print(f"[*] ìƒˆ ì½˜í…ì¸  ë°œê²¬! ({sub}): {post['title'][:30]}...")
                search_query = " ".join(post['title'].split()[:3])
                korean_trends = self.searcher.search_korean_trends(search_query)
                processed_text = self.processor.process_post(post, korean_trends=korean_trends)
                if not processed_text: continue
                parsed_data = self.parse_claude_result(processed_text)
                
                img_prompt = parsed_data.get('image_prompt', "Professional photography")
                image_filename = f"thumb_{post['id']}.png"
                self.painter.generate_image(img_prompt, image_filename)
                
                os.makedirs("public/images", exist_ok=True)
                if os.path.exists(f"data/images/{image_filename}"):
                    # Windowsì—ì„œ ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•  ê²½ìš° ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ os.replace ì‚¬ìš©
                    import shutil
                    shutil.move(f"data/images/{image_filename}", f"public/images/{image_filename}")
                
                keywords_raw = parsed_data.get('keywords', "").replace("[", "").replace("]", "").split(",")
                search_keyword = "ì¸ê¸°ìƒí’ˆ"
                for kw in keywords_raw:
                    clean_kw = kw.strip()
                    if clean_kw and len(clean_kw) > 1:
                        search_keyword = clean_kw
                        break
                
                coupang_items = self.affiliate.search_products(search_keyword, limit=3)
                if not coupang_items:
                    fallback_kw = " ".join(parsed_data.get('title', '').split()[:2])
                    coupang_items = self.affiliate.search_products(fallback_kw, limit=3)

                # [DB ì €ì¥ ë¡œì§] íŒŒì¼ì„ ë§Œë“œëŠ” ëŒ€ì‹  Cloudflare D1ì— ì§ì ‘ INSERT
                safe_title = parsed_data.get('title', 'no_title').replace("'", "''")
                safe_summary = parsed_data.get('summary', '').replace("'", "''")
                # ë³¸ë¬¸ ë§ˆí¬ë‹¤ìš´ ê²°í•©
                full_content = f"## ğŸ’¡ í•µì‹¬ ìš”ì•½\n{parsed_data.get('summary')}\n\n{parsed_data.get('content')}"
                if coupang_items:
                    full_content += "\n\n---\n### ğŸ›’ ì¶”ì²œ ìƒí’ˆ\n"
                    for item in coupang_items:
                        full_content += f"- **[{item['name']}]({item['link']})** ({item['price']}ì›)\n"
                    full_content += "\n*ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µë°›ìŠµë‹ˆë‹¤.*\n"
                
                safe_content = full_content.replace("'", "''")
                slug = f"{today_str}-{post['id']}"
                image_url = f"/images/{image_filename}"
                
                print(f"[*] DBì— í¬ìŠ¤íŒ… ì €ì¥ ì¤‘: {safe_title}")
                
                # D1 ì‹¤í–‰ (ì›ê²© ë°°í¬ëœ DBì— ì¦‰ì‹œ ë°˜ì˜)
                db_name = "auto-blog-db" # ì‹¤ì œ D1 ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
                sql = f"INSERT INTO posts (slug, title, summary, content, category, image_url) VALUES ('{slug}', '{safe_title}', '{safe_summary}', '{safe_content}', '{category_name}', '{image_url}');"
                
                # ì„ì‹œ SQL íŒŒì¼ ìƒì„±
                with open("temp.sql", "w", encoding="utf-8") as f:
                    f.write(sql)
                
                # D1 ì‹¤í–‰
                os.system(f"npx wrangler d1 execute {db_name} --remote --file=temp.sql --yes")
                os.remove("temp.sql")

                self.mark_as_processed(post['id'], parsed_data.get('title'), f"db://{slug}")
                print(f"[+++] DB ë°œí–‰ ì™„ë£Œ: {slug}")
                
                # ì´ë¯¸ì§€ íŒŒì¼ì€ ì—¬ì „íˆ ê¹ƒí—ˆë¸Œì— ì˜¬ë ¤ì•¼ í•¨ (public/images)
                os.system("git add public/images/*")
                os.system(f"git commit -m \"Image: {image_filename}\"")
                os.system("git push origin main")
                
                published_in_sub = True
                time.sleep(5)
                break # í•œ ê°œì˜ ê¸€ì„ ë°œí–‰í–ˆìœ¼ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™

            if not published_in_sub:
                print(f"[-] {sub} ì¹´í…Œê³ ë¦¬ì— ìƒˆë¡œ ë°œí–‰í•  ìˆ˜ ìˆëŠ” ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")

        print("\n" + "="*60)
        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ.")
        print("="*60)

if __name__ == "__main__":
    manager = GTBManager()
    manager.run_pipeline()
